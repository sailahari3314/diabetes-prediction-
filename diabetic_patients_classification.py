# -*- coding: utf-8 -*-
"""10July_Diabetic_patients_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ODvIHA2EERi7RsQe7hSwni4_VYbY_Grp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('diabetes.csv')
df.head()

df.shape

df.isnull().sum()

df.dtypes

x = df.iloc[:,:-1]   # df.drop('Outcome',axis=1)
y = df.iloc[:,-1]   # df['Outcome']
print(x.shape)
print(y.shape)
print(type(x))
print(type(y))

x.head()

y.head()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

768*0.75

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score

def gen_metrics(ytest,ypred):
    cm = confusion_matrix(ytest,ypred)
    print('confusion matrix\n',cm)
    print('Classification report\n',classification_report(ytest,ypred))
    print('Acc score',accuracy_score(ytest,ypred))

"""#### Build Models

#### 1) Log Reg
"""

from sklearn.linear_model import LogisticRegression

m1 = LogisticRegression(max_iter=1000)
m1.fit(x_train,y_train)

print('Training score',m1.score(x_train,y_train))
print('Testing score',m1.score(x_test,y_test))

ypred_m1 = m1.predict(x_test)
print(ypred_m1)

gen_metrics(y_test,ypred_m1)

"""#### 2) KNN"""

from sklearn.neighbors import KNeighborsClassifier

m2 = KNeighborsClassifier(n_neighbors=17)
m2.fit(x_train,y_train)

print('Training score',m2.score(x_train,y_train))
print('Testing score',m2.score(x_test,y_test))

ypred_m2 = m2.predict(x_test)
print(ypred_m2)

gen_metrics(y_test,ypred_m2)

"""### 3) DT"""

from sklearn.tree import DecisionTreeClassifier

m3 = DecisionTreeClassifier(criterion='gini',max_depth=5,min_samples_split=15)
#
m3.fit(x_train,y_train)

print('Training score',m3.score(x_train,y_train))
print('Testing score',m3.score(x_test,y_test))

ypred_m3 = m3.predict(x_test)
print(ypred_m3)

gen_metrics(y_test,ypred_m3)

"""#### 4) Random Forest"""

from sklearn.ensemble import RandomForestClassifier

m4 = RandomForestClassifier(n_estimators=50,criterion='entropy',max_depth=6,min_samples_split=12)
m4.fit(x_train,y_train)

print('Training score',m4.score(x_train,y_train))
print('Testing score',m4.score(x_test,y_test))

ypred_m4 = m4.predict(x_test)
print(ypred_m4)

gen_metrics(y_test,ypred_m4)

"""#### 5) SVM"""

from sklearn.svm import SVC

m5 = SVC(kernel='linear',C=1)
m5.fit(x_train,y_train)

print('Training score',m5.score(x_train,y_train))
print('Testing score',m5.score(x_test,y_test))

ypred_m5 = m5.predict(x_test)
print(ypred_m5)

gen_metrics(y_test,ypred_m5)

"""#### Conclusion
1) Log_Reg is the best performining model in terms of accuracy.<br>
2) Log_Reg and SVC are the best performining model in terms of recall<br>
"""

